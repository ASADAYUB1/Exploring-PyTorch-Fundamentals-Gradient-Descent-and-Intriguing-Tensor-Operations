{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0ed767",
   "metadata": {},
   "source": [
    "#  Some Interesting PyTorch tensor operations with Examples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4c638",
   "metadata": {},
   "source": [
    "## PyTorch:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e62b6a",
   "metadata": {},
   "source": [
    "PyTorch is a Python-Python based scientific computing package. It's mainly used for applications such as computer vision and natural language processing. The flexibility of PyTorch allow easy integration of new data types and algorithms, and the framework is also efficient and scalable. It was designed to minimize the number of computations required and to be compatible with a variety of hardware architectures. Two broad purposes of PyTorch are:\n",
    "\n",
    "* A replacement for NumPy to use the power of GPUs and other accelerators.\n",
    "* An automatic differentiation library that is useful to implement neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee016b8",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a44631",
   "metadata": {},
   "source": [
    "A tensor is a number, vector. matrix or any n-dimensional array. These are the fundamental data structures in deep learning, which are very similar to arrays and matrics, with which we can efficiently perform mathematical operations on large sets of data. A tensor can be represented as a matrix, but also as a vector, a scalar, or a higher-dimensional array. \n",
    "\n",
    "To make it easier to visualize, we can think of a tensor as a simple array containing scalars or other arrays. On PyTorch, a tensor is a structure very similar to a **ndarry**, with the difference that they are capable of running on a GPU, which dramatically speeds up the computational process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3505bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8961cd8e",
   "metadata": {},
   "source": [
    "## Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172b53c0",
   "metadata": {},
   "source": [
    "## Function 1 - torch.tensor\n",
    "\n",
    "To create tensors with Pytorch we can simply use the tensor() method:\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "torch.tensor(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4a1d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 6.],\n",
       "        [2., 4.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 \n",
    "\n",
    "torch.tensor([[3, 6], [2, 4.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c72dedc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 \n",
    "\n",
    "a_data = [[1., 2., 3.], [4, 5, 6]] \n",
    "a = torch.tensor(a_data) \n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d177faf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 2 at dim 1 (got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example 3 - breaking (to illustrate when it breaks)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]])\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 2 at dim 1 (got 3)"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking\n",
    "torch.tensor([[1, 2], [3, 4, 5]]) # No of element should be same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f60dfb",
   "metadata": {},
   "source": [
    "## Function 2 - randint() \n",
    "\n",
    "The randint() method returns a tensor filled with random integers generated uniformly between low (inclusive) and high (exclusive) for a given shape. The shape is given by the user which can be a tuple or a list with non-negative members. The default value for low is 0. When only one int argument is passed, low gets the value 0, by default, and high gets the passed value.\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "torch.randint(low,high,shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "205e5d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 4],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 \n",
    "\n",
    "randint_tensor_a = torch.randint(2,5, (2,2)) \n",
    "print(randint_tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80773dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [1, 2],\n",
      "        [2, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "\n",
    "randint_tensor = torch.randint(0,3, (3,2)) \n",
    "print(randint_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4c596c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randint(): argument 'size' (position 2) must be tuple of ints, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example 3 - breaking (to illustrate when it breaks)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m randint_tensor_c \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m3\u001b[39m)) \n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(randint_tensor)\n",
      "\u001b[1;31mTypeError\u001b[0m: randint(): argument 'size' (position 2) must be tuple of ints, not int"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "\n",
    "randint_tensor_c = torch.randint(1, (3)) \n",
    "print(randint_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9fd69c",
   "metadata": {},
   "source": [
    "## Function 3 - complex()\n",
    "\n",
    "The complex() method takes two arguments (real and imag) and returns a complex tensor with its real part equal to real and its imaginary part equal to imag where both real and imag are tensors having the same datatype and same shape.\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "torch.complex(real tensor,another real tensor which is to be used as imaginary part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24c7736a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4356, 0.7506],\n",
      "        [0.5335, 0.6262]])\n",
      "tensor([[0.1342, 0.0804],\n",
      "        [0.2047, 0.0685]])\n",
      "tensor([[0.4356+0.1342j, 0.7506+0.0804j],\n",
      "        [0.5335+0.2047j, 0.6262+0.0685j]])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 \n",
    "\n",
    "a_real = torch.rand(2, 2) \n",
    "print(a_real) \n",
    "a_imag = torch.rand(2, 2) \n",
    "print(a_imag) \n",
    "a_complex_tensor = torch.complex(a_real, a_imag) \n",
    "print(a_complex_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a9bdeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5516, 0.3566, 0.1326],\n",
      "        [0.0870, 0.7649, 0.4876],\n",
      "        [0.0647, 0.9627, 0.7627],\n",
      "        [0.5156, 0.8200, 0.3522]])\n",
      "tensor([[0.4803, 0.5671, 0.8102],\n",
      "        [0.3770, 0.5989, 0.8159],\n",
      "        [0.4721, 0.8255, 0.5843],\n",
      "        [0.9182, 0.7669, 0.1143]])\n",
      "tensor([[0.5516+0.4803j, 0.3566+0.5671j, 0.1326+0.8102j],\n",
      "        [0.0870+0.3770j, 0.7649+0.5989j, 0.4876+0.8159j],\n",
      "        [0.0647+0.4721j, 0.9627+0.8255j, 0.7627+0.5843j],\n",
      "        [0.5156+0.9182j, 0.8200+0.7669j, 0.3522+0.1143j]])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 \n",
    "\n",
    "b_real = torch.rand(4, 3) \n",
    "print(b_real) \n",
    "b_imag = torch.rand(4, 3) \n",
    "print(b_imag) \n",
    "b_complex_tensor = torch.complex(b_real, b_imag) \n",
    "print(b_complex_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce4d16ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2599, 0.4582]])\n",
      "tensor([])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (0) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m imag \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m0\u001b[39m) \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(imag) \n\u001b[1;32m----> 7\u001b[0m complex_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcomplex(real, imag) \n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(complex_tensor)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (0) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking\n",
    "\n",
    "real = torch.rand(1, 2) \n",
    "print(real) \n",
    "imag = torch.rand(0) \n",
    "print(imag) \n",
    "complex_tensor = torch.complex(real, imag) \n",
    "print(complex_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cfeb88",
   "metadata": {},
   "source": [
    "## Function 4 - reshape()\n",
    "\n",
    "This method allows us to change the shape with the same data and number of elements as self but with the specified shape, which means it returns the same data as the specified array, but with different specified dimension sizes.\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "torch.reshape(input, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fde4f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 \n",
    "\n",
    "a = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "print(a) \n",
    "print(a.reshape([4, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0618e885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "\n",
    "a = torch.tensor([[1,2,3],[4,5,6]])\n",
    "torch.reshape(a, (6,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "697a501c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reshape(): argument 'shape' (position 2) must be tuple of ints, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example 3 - breaking \u001b[39;00m\n\u001b[0;32m      3\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m],[\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]])\n\u001b[1;32m----> 4\u001b[0m torch\u001b[38;5;241m.\u001b[39mreshape(a, (\u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: reshape(): argument 'shape' (position 2) must be tuple of ints, not int"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking \n",
    "\n",
    "a = torch.tensor([[1,2,3],[4,5,6]])\n",
    "torch.reshape(a, (6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d696f",
   "metadata": {},
   "source": [
    "## Function 5 - view() \n",
    "\n",
    "view() is used to change the tensor in two-dimensional format IE rows and columns. We have to specify the number of rows and the number of columns to be viewed.\n",
    "\n",
    "**Syntax:** \n",
    "\n",
    "tensor.view(no_of_rows,no_of_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f26ead9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24., 56., 10., 20., 30., 40., 50.,  1.,  2.,  3.,  4.,  5.])\n",
      "tensor([[24., 56., 10.],\n",
      "        [20., 30., 40.],\n",
      "        [50.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.]])\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "\n",
    "a=torch.FloatTensor([24, 56, 10, 20, 30, \n",
    "                     40, 50, 1, 2, 3, 4, 5])  \n",
    "\n",
    "print(a)\n",
    "print(a.view(4, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15adaff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24., 56., 10., 20., 30., 40., 50.,  1.,  2.,  3.])\n",
      "tensor([[24., 56.],\n",
      "        [10., 20.],\n",
      "        [30., 40.],\n",
      "        [50.,  1.],\n",
      "        [ 2.,  3.]])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 \n",
    "\n",
    "b = torch.FloatTensor([24, 56, 10, 20, 30,\n",
    "                     40, 50, 1, 2, 3])  \n",
    " \n",
    "print(b)\n",
    "print(b.view(5, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f818037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24., 56., 10., 20., 30., 40., 50.,  1.,  2.,  3.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[6, 2]' is invalid for input of size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m c \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m56\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m      5\u001b[0m                      \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])  \n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(c)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(c\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[6, 2]' is invalid for input of size 10"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking\n",
    "\n",
    "\n",
    "c = torch.FloatTensor([24, 56, 10, 20, 30,\n",
    "                     40, 50, 1, 2, 3])  \n",
    " \n",
    "print(c)\n",
    "print(c.view(6, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28ace09",
   "metadata": {},
   "source": [
    "## Function 6 - take()\n",
    "\n",
    "Returns a new tensor with the elements of input at the given indices. The input tensor is treated as if it were viewed as a 1-D tensor. The result takes the same shape as the indices\n",
    "\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "torch.take(input, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3da9c704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 7])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 \n",
    "\n",
    "a = torch.tensor([[1,2,3],\n",
    "                  [3, 4,7],\n",
    "                  [4,5,6]])\n",
    "torch.take(a, torch.tensor([1,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d98e541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 4, 6, 7])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 \n",
    "\n",
    "a = torch.tensor([[1,2,3],\n",
    "                  [3, 4,7],\n",
    "                  [4,5,6]])\n",
    "torch.take(a, torch.tensor([0,3,6,8,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97b63bbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "out of range: tried to access index 10 on a tensor of 9 elements.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example 3 - breaking \u001b[39;00m\n\u001b[0;32m      3\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m      4\u001b[0m                   [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m7\u001b[39m],\n\u001b[0;32m      5\u001b[0m                   [\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]])\n\u001b[1;32m----> 6\u001b[0m torch\u001b[38;5;241m.\u001b[39mtake(a, torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m10\u001b[39m]))\n",
      "\u001b[1;31mIndexError\u001b[0m: out of range: tried to access index 10 on a tensor of 9 elements."
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking \n",
    "\n",
    "a = torch.tensor([[1,2,3],\n",
    "                  [3, 4,7],\n",
    "                  [4,5,6]])\n",
    "torch.take(a, torch.tensor([0,3,6,8,10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ddb9bb",
   "metadata": {},
   "source": [
    "## Function 7 - .unbind()\n",
    "\n",
    "It's used to removes a tensor dimension. It will returns a tuple of all slices along a given dimension, already without it.\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "torch.unbind(input, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "289ee8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), tensor([3, 4, 7]), tensor([4, 5, 6]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 \n",
    "\n",
    "a = torch.tensor([[1,2,3],\n",
    "                  [3, 4,7],\n",
    "                  [4,5,6]])\n",
    "torch.unbind(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f5eda48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 3, 4]), tensor([2, 4, 5]), tensor([3, 7, 6]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 \n",
    "\n",
    "a = torch.tensor([[1,2,3],\n",
    "                  [3, 4,7],\n",
    "                  [4,5,6]])\n",
    "torch.unbind(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08106d8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example 3 - breaking\u001b[39;00m\n\u001b[0;32m      3\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m      4\u001b[0m                   [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m7\u001b[39m],\n\u001b[0;32m      5\u001b[0m                   [\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]])\n\u001b[1;32m----> 6\u001b[0m torch\u001b[38;5;241m.\u001b[39munbind(a, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking\n",
    "\n",
    "a = torch.tensor([[1,2,3],\n",
    "                  [3, 4,7],\n",
    "                  [4,5,6]])\n",
    "torch.unbind(a, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a5e67f",
   "metadata": {},
   "source": [
    "## Function 8 - reciprocal()\n",
    "\n",
    "It's returns a new tensor with the reciprocal of the elements of input.\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "torch.reciprocal(input, out=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cb3d277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6250, 0.4000],\n",
       "        [0.3333, 0.2500],\n",
       "        [0.2000, 0.1667]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 \n",
    "\n",
    "torch.reciprocal(torch.tensor([[1.6,2.5],[3,4],[5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b0dedb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.5000],\n",
       "        [0.3333, 0.2500],\n",
       "        [0.2000, 0.1667]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 \n",
    "\n",
    "a = torch.tensor([[1.0,2],[3,4],[5,6]])\n",
    "torch.reciprocal(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36f989ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reciprocal() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example 3 - breaking \u001b[39;00m\n\u001b[0;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m      3\u001b[0m                   [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m7\u001b[39m],\n\u001b[0;32m      4\u001b[0m                   [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]])\n\u001b[1;32m----> 5\u001b[0m torch\u001b[38;5;241m.\u001b[39mreciprocal(a,\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: reciprocal() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking \n",
    "a = torch.tensor([[1,2,3],\n",
    "                  [3, 4,7],\n",
    "                  [1,5,6]])\n",
    "torch.reciprocal(a,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfa40bf",
   "metadata": {},
   "source": [
    "## Function 9 - torch.t()\n",
    "\n",
    "Transposition in tensor operations is the process of flipping the axes of a tensor. It involves exchanging the rows and columns of a 2D tensor or more generally, the axes of a tensor of any dimension.\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "torch.t() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6220518c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 8],\n",
      "        [5, 6]])\n",
      "tensor([[3, 5],\n",
      "        [8, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 \n",
    "\n",
    "E = torch.tensor([ [3, 8], [5, 6]])\n",
    "F = torch.t(E)\n",
    "print(E)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d64166b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  5],\n",
      "        [ 4,  8],\n",
      "        [ 6, 10]])\n",
      "tensor([[ 2,  4,  6],\n",
      "        [ 5,  8, 10]])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 \n",
    "\n",
    "E = torch.tensor([[ 2, 5], [ 4, 8], [ 6, 10]])\n",
    "F = torch.t(E)\n",
    "print(E)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21ae3b26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 1 at dim 1 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example 3 - breaking \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m E \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([ [\u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]])\n\u001b[0;32m      4\u001b[0m F \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mt(E)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(E)\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 1 at dim 1 (got 2)"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking \n",
    "\n",
    "E = torch.tensor([ [3], [5, 6]])\n",
    "F = torch.t(E)\n",
    "print(E)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85cb79e",
   "metadata": {},
   "source": [
    "## Function 10 - cat()\n",
    "\n",
    "Concatenation in tensor operations is the process of joining two or more tensors along a specific dimension to form a larger tensor. The resulting tensor has a new dimension that is the concatenation of the original dimensions of the input tensors.\n",
    "\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "torch.cat() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "621c2753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 \n",
    "\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6]])\n",
    "\n",
    "c = torch.cat((a, b), dim=0)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ec943a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 5, 6],\n",
      "        [3, 4, 9, 4, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 \n",
    "\n",
    "\n",
    "a = torch.tensor([[1, 2, 3], [3, 4, 9]])\n",
    "b = torch.tensor([[5, 6], [4, 6]])\n",
    "\n",
    "c = torch.cat((a, b), dim=1)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39d10500",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]])\n\u001b[0;32m      5\u001b[0m b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]])\n\u001b[1;32m----> 7\u001b[0m c \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((a, b), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(c)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 3)"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking \n",
    "\n",
    "\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6]])\n",
    "\n",
    "c = torch.cat((a, b), dim=3)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fb85d8",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "Provide links to your references and other interesting articles about tensors\n",
    "* Official documentation for tensor operations: https://pytorch.org/docs/stable/torch.html\n",
    "* Difference between a matrix and a tensor: https://medium.com/@quantumsteinke/whats-the-difference-between-a-matrix-and-a-tensor-4505fbdc576c\n",
    "* https://gist.github.com/jonhare/d98813b2224dddbb234d2031510878e1?permalink_comment_id=3166373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08364bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
